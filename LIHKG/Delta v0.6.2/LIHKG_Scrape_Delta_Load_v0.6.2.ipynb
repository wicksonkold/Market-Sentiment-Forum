{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af0a99f",
   "metadata": {},
   "source": [
    "bs4, uc drive, selenium, deep-translator, snow-nlp, schedule, spacytextblob, spacy\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_experimental_option(\n",
    "    \"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument('lang=zh-CN,zh,zh-TW,en-US,en')\n",
    "chrome_options.add_argument(\n",
    "    'user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36')\n",
    "chrome_options.add_argument(\"disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_argument(\"proxy-server=socks5://127.0.0.1:1080\")\n",
    "preferences = {\n",
    "    \"webrtc.ip_handling_policy\": \"disable_non_proxied_udp\",\n",
    "    \"webrtc.multiple_routes_enabled\": False,\n",
    "    \"webrtc.nonproxied_udp_enabled\": False\n",
    "}\n",
    "\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b88198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Admin/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import langid\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import undetected_chromedriver as uc\n",
    "from datetime import timedelta, date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from snownlp import SnowNLP\n",
    "import pycantonese\n",
    "from pycantonese.word_segmentation import Segmenter\n",
    "from deep_translator import GoogleTranslator\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d553df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def click_thread(driver, idx):\n",
    "    #click thread\n",
    "    auto_xpath = f'//*[@id=\"leftPanel\"]/div[2]/div[{idx + 1}]/div/div[2]/a[1]'\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, auto_xpath).click()\n",
    "        #print(idx)\n",
    "    except:\n",
    "        #print(\"skip\")\n",
    "        pass\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "def scroll_left_panel(driver):\n",
    "    counter = 0\n",
    "    while True:\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        checker = soup.find_all(\"div\",{\"class\":\"_21IQKhlBjN2jlHS_TVgI3l\"})\n",
    "        \n",
    "        counter = counter + 1 \n",
    "        previous_checker = len(checker)\n",
    "        if counter == 10:\n",
    "            try:\n",
    "                if len(checker) == previous_checker:\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME, '_33r1FGqGJZF-fM1VZm7mhN').text\n",
    "            time.sleep(2)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for i in range(20):\n",
    "            ActionChains(driver)\\\n",
    "                .send_keys(\" \")\\\n",
    "                .perform()\n",
    "            time.sleep(0.1)\n",
    "\n",
    "def risk_checker(text):\n",
    "    others_check = \"False\"\n",
    "    for i in cr_keyword:\n",
    "        if i in text:\n",
    "            risk = 'Credit Risk'\n",
    "            return risk\n",
    "        \n",
    "\n",
    "    for i in lr_keyword:\n",
    "        if i in text:\n",
    "            lr_check = 'True'\n",
    "            risk = 'Liquidity Risk'\n",
    "            return risk\n",
    "\n",
    "    for i in mr_keyword:\n",
    "        if i in text:\n",
    "            mr_check = 'True'\n",
    "            risk = 'Market Risk'\n",
    "            return risk\n",
    "\n",
    "    for i in tr_keyword:\n",
    "        if i in text:\n",
    "            tr_check = 'True'\n",
    "            risk = 'Technology Risk'\n",
    "            return risk\n",
    "\n",
    "    for i in or_keyword:\n",
    "        if i in text:\n",
    "            or_check = 'True'\n",
    "            risk = 'Operation Risk'\n",
    "            return risk\n",
    "\n",
    "    risk = 'Unidentified'    \n",
    "    return risk\n",
    "\n",
    "def word_risk_checker(text):\n",
    "    others_check = \"False\"\n",
    "\n",
    "    if text in cr_keyword:\n",
    "        risk = 'Credit Risk'\n",
    "        return risk\n",
    "\n",
    "    if text in lr_keyword:\n",
    "        lr_check = 'True'\n",
    "        risk = 'Liquidity Risk'\n",
    "        return risk\n",
    "\n",
    "    if text in mr_keyword:\n",
    "        mr_check = 'True'\n",
    "        risk = 'Market Risk'\n",
    "        return risk\n",
    "\n",
    "    if text in tr_keyword:\n",
    "        tr_check = 'True'\n",
    "        risk = 'Technology Risk'\n",
    "        return risk\n",
    "\n",
    "    if text in or_keyword:\n",
    "        or_check = 'True'\n",
    "        risk = 'Operation Risk'\n",
    "        return risk\n",
    "\n",
    "    risk = 'Unidentified'    \n",
    "    return risk\n",
    "\n",
    "def words_segmentation(keywords_set, foul_keywords, skip_keywords, context, comment_uid, comment_datetime):\n",
    "    #use the customized word list for the nlp\n",
    "    segmenter = Segmenter(allow= keywords_set,max_word_length=8)\n",
    "    comment_foul = \"False\"\n",
    "    idx = 0\n",
    "    context = context.split(\" \")\n",
    "    \n",
    "    for block_context in context:\n",
    "        #segment the sentence\n",
    "        segmented_list = pycantonese.segment(block_context, cls=segmenter)\n",
    "        segmented_list = pycantonese.pos_tag(segmented_list)\n",
    "\n",
    "        for word, pos in segmented_list:\n",
    "            word = word.title()\n",
    "            if word in skip_keywords:\n",
    "                continue\n",
    "\n",
    "            if pos == 'ADJ' or pos == 'NOUN' or pos == 'VERB':\n",
    "                if word in foul_keywords:\n",
    "                    f_word = \"True\"\n",
    "                    comment_foul = \"True\"\n",
    "                else:\n",
    "                    f_word = \"False\"\n",
    "                #check chi or eng\n",
    "                lang, score = langid.classify(word)\n",
    "                \n",
    "                word_uid = comment_uid+ '-' + str(idx).zfill(8)\n",
    "                idx = idx + 1 \n",
    "                \n",
    "                '''\n",
    "                #generate sentiment score\n",
    "                snow_stm = SnowNLP(word)\n",
    "                sentiment_score = snow_stm.sentiments\n",
    "                \n",
    "                #Sentiment Mood\n",
    "                sentiment = \"Neutral\"\n",
    "                if sentiment_score >= 0.6:\n",
    "                    sentiment = \"Positive\"\n",
    "                if sentiment_score <= 0.4:\n",
    "                    sentiment = \"Negative\"\n",
    "                '''\n",
    "                word_risk = word_risk_checker(word)\n",
    "                #t_word = translate_to_en(word)\n",
    "                #t_sentiment, t_sentiment_score = word_sentiment_check(t_word)\n",
    "                \n",
    "                df_words.loc[len(df_words)]= [word_uid,\n",
    "                                              comment_uid,\n",
    "                                              comment_datetime,   \n",
    "                                              lang,\n",
    "                                              pos,\n",
    "                                              word.title(),\n",
    "                                              f_word.title(),\n",
    "                                              word_risk\n",
    "                                              #sentiment,\n",
    "                                              #sentiment_score,\n",
    "                                              #str(t_word).title(),\n",
    "                                              #t_sentiment,\n",
    "                                              #t_sentiment_score\n",
    "                                             ]\n",
    "    return comment_foul\n",
    "\n",
    "\n",
    "def translate_to_en(text):\n",
    "    try:\n",
    "        #translate to english\n",
    "        translated = GoogleTranslator(source='zh-TW', target='en').translate(text)\n",
    "    except:\n",
    "        translated = text\n",
    "    return translated\n",
    "\n",
    "###############################\n",
    "#Not used due to not effactive \n",
    "\n",
    "def sentiment_check(text):\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        polarity = doc._.blob.polarity            \n",
    "        subjectivity = doc._.blob.subjectivity\n",
    "\n",
    "        if polarity >= 0.15:\n",
    "            sentiment = 'Positive'\n",
    "        elif polarity <= -0.15:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "\n",
    "        if subjectivity >= 0.5:\n",
    "            perception = 'Subjective'\n",
    "        else:\n",
    "            perception = 'Objective'\n",
    "    except:\n",
    "        sentiment = 'Neutral'\n",
    "        polarity = 0\n",
    "        perception = 'Objective'\n",
    "        subjectivity = 0\n",
    "        \n",
    "    return sentiment, polarity, perception, subjectivity\n",
    "\n",
    "##############################\n",
    "#Not used...\n",
    "def word_sentiment_check(text):\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        polarity = doc._.blob.polarity            \n",
    "        if polarity >= 0.15:\n",
    "            sentiment = 'Positive'\n",
    "        elif polarity <= -0.15:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "    except:\n",
    "        sentiment = 'Neutral'\n",
    "        polarity = 0\n",
    " \n",
    "    return sentiment, polarity\n",
    "###############################\n",
    "                                              \n",
    "def vader_sentiment(text):\n",
    "    try:\n",
    "        sent_analyzer = SentimentIntensityAnalyzer()\n",
    "        result = sent_analyzer.polarity_scores(text)\n",
    "        score = result['compound']\n",
    "        sentiment = \"neutral\"\n",
    "\n",
    "        if(result['compound']>= 0.05):\n",
    "            sentiment = \"positive\"\n",
    "\n",
    "        elif(result['compound']<= -0.05):\n",
    "            sentiment = \"negative\"\n",
    "    except:\n",
    "        sentiment = \"neutral\"\n",
    "        score = '0'\n",
    "    return sentiment, score\n",
    "\n",
    "###################\n",
    "#OLD VERSION\n",
    "'''\n",
    "# NEED TO CHECK IF THE THREAD EXIST OR NOT FIRST\n",
    "# Return True == need to update\n",
    "# Return False == skip it\n",
    "def left_panel_date_check(previous_extract_latest_comment_time, embedded_date):\n",
    "    checker = False\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    current_datetime = datetime.strptime(current_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    splited_embedded_date = embedded_date.split(\" \")\n",
    "    \n",
    "    previous_extract_latest_comment_time = datetime.strptime(previous_extract_latest_comment_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    if splited_embedded_date[1] == '分鐘前':\n",
    "        decrypted_embedded_datetime = current_datetime - relativedelta(hours = int(splited_embedded_date[0]))\n",
    "        if previous_extract_latest_comment_time < decrypted_embedded_datetime:\n",
    "            checker = True\n",
    "            return checker\n",
    "        else:\n",
    "            checker = False\n",
    "            return checker\n",
    " \n",
    "    elif splited_embedded_date[1] == '小時前':\n",
    "        decrypted_embedded_datetime = current_datetime - relativedelta(hours = int(splited_embedded_date[0]))\n",
    "        if previous_extract_latest_comment_time < decrypted_embedded_datetime:\n",
    "            checker = True\n",
    "            return checker\n",
    "        else:\n",
    "            checker = False\n",
    "            return checker\n",
    "    else:\n",
    "        checker = False\n",
    "        return checker\n",
    "'''\n",
    "###################\n",
    "\n",
    "def left_panel_date_check(previous_extract_latest_comment_time, embedded_date):\n",
    "    checker = False\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    current_datetime = datetime.strptime(current_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    splited_embedded_date = embedded_date.split(\" \")\n",
    "    \n",
    "    previous_extract_latest_comment_time = datetime.strptime(previous_extract_latest_comment_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    if splited_embedded_date[1] == '分鐘前':\n",
    "        decrypted_embedded_datetime = current_datetime - relativedelta(hours = int(splited_embedded_date[0]))\n",
    "        print('P1')\n",
    "        print(previous_extract_latest_comment_time, decrypted_embedded_datetime)\n",
    "        if previous_extract_latest_comment_time < decrypted_embedded_datetime:\n",
    "            checker = True\n",
    "            return checker\n",
    "        else:\n",
    "            checker = False\n",
    "            return checker\n",
    " \n",
    "    elif splited_embedded_date[1] == '小時前':\n",
    "        if int(splited_embedded_date[0]) > 1:\n",
    "            checker = False\n",
    "            return checker\n",
    "        else:\n",
    "            checker = True\n",
    "            return checker\n",
    "    else:\n",
    "        checker = False\n",
    "        return checker\n",
    "    \n",
    "def check_thread_date_range(soup, user_customized_time_int_month):\n",
    "    all_comment = soup.find_all(\"div\",{\"class\":\"_36ZEkSvpdj_igmog0nluzh\"})\n",
    "    floor_zero = all_comment[0]\n",
    "    floor_zero_datetime = floor_zero.find(\"span\",{\"class\":\"Ahi80YgykKo22njTSCzs_\"})\n",
    "    new_floor_zero_datetime = str(floor_zero_datetime).split(\"\\\"\")[5]\n",
    "    new_floor_zero_datetime = new_floor_zero_datetime.replace('年',\"-\").replace('月', \"-\").replace('日', \"\")\n",
    "    floor_zero_date = new_floor_zero_datetime.split(\" \")[0]\n",
    "\n",
    "\n",
    "    floor_zero_thread_time = datetime.strptime(floor_zero_date, '%Y-%m-%d').date()\n",
    "    floor_zero_cur_time = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    floor_zero_cur_time = datetime.strptime(floor_zero_cur_time, '%Y-%m-%d').date()\n",
    "    \n",
    "    date_out_of_range = False\n",
    "    if floor_zero_thread_time < floor_zero_cur_time - relativedelta(months = user_customized_time_int_month):\n",
    "        date_out_of_range = True\n",
    "        print('OUT OF RANGE... break')\n",
    "    return date_out_of_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f270d1a-536f-4942-9520-ed36cf1834f1",
   "metadata": {},
   "source": [
    "### HKMA PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562a60fc-160c-450e-bd0e-d12294b16e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ma_storage_dsl_path = '/mnt/prototypehkmastorage1/Web-Scraping SuT/LIHKG/Storage/'\n",
    "#ma_required_file_dsl_path = '/mnt/prototypehkmastorage1/Web-Scraping SuT/LIHKG/Required_Files/'\n",
    "#chrome_drive_dsl_path = '/mnt/prototypehkmastorage1/Web-Scraping SuT/LIHKG/Required_Files/chromedriver'\n",
    "\n",
    "ma_storage_dsl_path = ''\n",
    "ma_required_file_dsl_path = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f851aed-afc4-4da7-a557-43b4af173c84",
   "metadata": {},
   "source": [
    "### Set Time Range (Month & int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b78e2e-e93c-4a7d-ab8e-0cc5c5ac2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_customized_time_int_month = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd2c24-8d5e-4765-a849-8bc3f9653138",
   "metadata": {},
   "source": [
    "### Storage File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d28833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required File\n",
    "#Open pandas\n",
    "try:\n",
    "    df_thread_log = pd.read_excel(f'{ma_storage_dsl_path}Thread_Log.xlsx')\n",
    "except:\n",
    "    df_thread_log = pd.DataFrame(columns=[\"Platform UID\",\n",
    "                                       \"Thread UID (PK)\",\n",
    "                                       \"Search Keyword\",\n",
    "                                       \"Reference Bank\",\n",
    "                                       \"Thread Create Datetime\",\n",
    "                                       \"Thread Author\",\n",
    "                                       \"Thread Title\",\n",
    "                                       \"Thread Theme\",\n",
    "                                       \"Comment Floor Number (Latest)\",\n",
    "                                       \"Risk Type\",\n",
    "                                       \"Thread Latest Comment Time\"])\n",
    "    \n",
    "try:\n",
    "    df_fetch_log = pd.read_excel(f'{ma_storage_dsl_path}Fetch_Log.xlsx')\n",
    "except:\n",
    "    df_fetch_log = pd.DataFrame(columns=[\"Fetch UID (PK)\",\n",
    "                                       \"Thread UID (FK)\",\n",
    "                                       \"Fetch Datetime\",\n",
    "                                       \"Thread Latest Comment Time(Thread info)\",\n",
    "                                       \"Thread Latest Comment Time(Fetch inside comment)\",\n",
    "                                       \"Thread Number of Page\",\n",
    "                                       \"Number of Share\",\n",
    "                                       \"Number of Reactions\",                                    \n",
    "                                       \"Thread Likes\",\n",
    "                                       \"Thread Dislike\",\n",
    "                                       \"Angry\", #\n",
    "                                       \"Heart\", #\n",
    "                                       \"HaHa\", #\n",
    "                                       \"Go For It\", #\n",
    "                                       \"Cry\", #\n",
    "                                       \"WOW\", #\n",
    "                                       \"Number of Comment\"])\n",
    "\n",
    "#Get Distinct value by last row\n",
    "\n",
    "try:\n",
    "    df_distinct_thread_by_latest = df_thread_log.drop_duplicates(subset=[ 'Thread Author',\n",
    "                                                                          'Thread Title',\n",
    "                                                                          'Thread Theme'], keep='last')\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    df_comments = pd.read_excel(f'{ma_storage_dsl_path}Comment_Log.xlsx')\n",
    "except:\n",
    "    df_comments = pd.DataFrame(columns=[\"Thread UID (FK)\",\n",
    "                                        \"Comment UID (PK)\",\n",
    "                                        \"Fetch Datetime\",\n",
    "                                        \"Comment Floor Number\",\n",
    "                                        \"Comment Author\",\n",
    "                                        \"Original Embedded Date\", #\n",
    "                                        \"Comment Datetime\",\n",
    "                                        \"Comment Date\",\n",
    "                                        \"Comment Time\",\n",
    "                                        \"Comment Likes\",\n",
    "                                        \"Comment Dislike\",\n",
    "                                        \"Comment Replies\",\n",
    "                                        \"Comment Context\",\n",
    "                                        \"Comment Context (Translated)\",\n",
    "                                        \"Sentiment\",\n",
    "                                        \"Sentiment Score\",\n",
    "                                        \"Risk Type (Comment Level)\",\n",
    "                                        #\"Perception\",\n",
    "                                        #\"Perception Score\",\n",
    "                                        \"Offensive Comment\"])   \n",
    "    \n",
    "try:\n",
    "    df_words = pd.read_excel(f'{ma_storage_dsl_path}Segmented_Words.xlsx')\n",
    "except:\n",
    "    df_words = pd.DataFrame(columns=[\"Word UID (PK)\",\n",
    "                                   \"Comment UID (FK)\",\n",
    "                                   \"Datetime (Comment)\",\n",
    "                                   \"Language\",\n",
    "                                   \"Part of Speech Tagging\",\n",
    "                                   \"Word\",\n",
    "                                   \"Foul Language\",\n",
    "                                   \"Risk Type (Word Level)\"])\n",
    "                                   #\"Sentiment\",\n",
    "                                   #\"Sentiment Score\",\n",
    "                                   #\"Word (Translated)\",\n",
    "                                   #\"Sentiment (Translated)\",\n",
    "                                   #\"Sentiment Score (Translated)\"\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07e516-faa7-466f-b84f-157ab85ca96e",
   "metadata": {},
   "source": [
    "### Required File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759e0eb8-d8ef-44ac-995f-a8a5dca9e404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Reference Bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>渣打</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>揸兜</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>滙豐</td>\n",
       "      <td>Hongkong and Shanghai Banking Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>匯豐</td>\n",
       "      <td>Hongkong and Shanghai Banking Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hsbc</td>\n",
       "      <td>Hongkong and Shanghai Banking Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>大貓銀行</td>\n",
       "      <td>Hongkong and Shanghai Banking Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>行山銀行</td>\n",
       "      <td>Hang Seng Bank Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>恆生</td>\n",
       "      <td>Hang Seng Bank Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>花旗銀行</td>\n",
       "      <td>Citibank (Hong Kong)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>citi</td>\n",
       "      <td>Citibank (Hong Kong)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>boc</td>\n",
       "      <td>Bank of China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>中銀</td>\n",
       "      <td>Bank of China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>中國銀行</td>\n",
       "      <td>Bank of China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Keyword                             Reference Bank\n",
       "0       渣打               Standard Chartered Hong Kong\n",
       "1       揸兜               Standard Chartered Hong Kong\n",
       "2       滙豐  Hongkong and Shanghai Banking Corporation\n",
       "3       匯豐  Hongkong and Shanghai Banking Corporation\n",
       "4     hsbc  Hongkong and Shanghai Banking Corporation\n",
       "5     大貓銀行  Hongkong and Shanghai Banking Corporation\n",
       "6     行山銀行                     Hang Seng Bank Limited\n",
       "7       恆生                     Hang Seng Bank Limited\n",
       "8     花旗銀行                       Citibank (Hong Kong)\n",
       "9     citi                       Citibank (Hong Kong)\n",
       "10     boc                              Bank of China\n",
       "11      中銀                              Bank of China\n",
       "12    中國銀行                              Bank of China"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Customized Keyword For NLP Checks\n",
    "df_keywords_NLP = pd.read_excel(f'{ma_required_file_dsl_path}Keywords_NLP.xlsx', index_col=None)\n",
    "keywords_NLP = df_keywords_NLP[\"Keyword\"].values.tolist()\n",
    "\n",
    "#Set empty set to store keywords and used by the pycantonese\n",
    "keywords_NLP_set = set()\n",
    "for i in keywords_NLP:\n",
    "    keywords_NLP_set.add(i)\n",
    "    \n",
    "#Get Foul Words\n",
    "df_foul_keywords = pd.read_excel(f'{ma_required_file_dsl_path}Keywords_Foul_Language.xlsx', index_col=None)\n",
    "foul_keywords = df_foul_keywords[\"Keyword\"].values.tolist()\n",
    "\n",
    "#Get Skip Words\n",
    "df_skip_keywords = pd.read_excel(f'{ma_required_file_dsl_path}Keywords_Skip.xlsx', index_col=None)\n",
    "skip_keywords = df_skip_keywords[\"Keyword\"].values.tolist()\n",
    "\n",
    "#Set language pack - lang identifer\n",
    "langid.set_languages(['zh', 'en'])\n",
    "#\n",
    "#\n",
    "###############\n",
    "\n",
    "#Set Vader\n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Set language pack - Spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_risk_type = pd.read_excel(f'{ma_required_file_dsl_path}Keywords_Risk.xlsx')\n",
    "cr_keyword = df_risk_type[\"CR\"].dropna().values.tolist()\n",
    "lr_keyword = df_risk_type[\"LR\"].dropna().values.tolist()\n",
    "mr_keyword = df_risk_type[\"MR\"].dropna().values.tolist()\n",
    "tr_keyword = df_risk_type[\"TR\"].dropna().values.tolist()\n",
    "or_keyword = df_risk_type[\"OR\"].dropna().values.tolist()\n",
    "    \n",
    "df_keyword = pd.read_excel(f'{ma_required_file_dsl_path}LIHKG_Keyword.xlsx', index_col=None)\n",
    "keyword_list = df_keyword[\"Keyword\"].values.tolist()\n",
    "ref_bank_list = df_keyword[\"Reference Bank\"].values.tolist()\n",
    "df_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458941dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword Check\n",
      "Loop 1 揸兜\n",
      "Start - loop thread\n",
      "尋日響foodcourt，見條港女揸住兜公仔麵撈芝士，韓狗食物真是狗也不hi\n",
      "Not found... Set floor pointer to 0\n",
      "Keyword not included in title... Skip it...\n",
      "睇嚟揸兜今日好唔掂喎⋯⋯\n",
      "Found... #4, 2022-12-7 23:15:47\n",
      "False no updates... check for the post date...\n",
      "False Didnt exceed the range... continue the loop \n",
      "揸兜信用卡比人碌到錢\n",
      "Found... #150, 2022-12-6 23:14:46\n",
      "False no updates... check for the post date...\n",
      "False Didnt exceed the range... continue the loop \n",
      "mpf咁撚樣搞 係咪以後65歲後個個揸兜？\n",
      "Not found... Set floor pointer to 0\n",
      "OUT OF RANGE... break\n",
      "Alert - Thread created date out of customized time range... Skip it...\n",
      "CPU times: user 391 ms, sys: 165 ms, total: 556 ms\n",
      "Wall time: 50.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "########\n",
    "# MAIN #\n",
    "########\n",
    "\n",
    "#set driver anti detect\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "#chrome_options.add_argument('--headless')\n",
    "chrome_options.add_experimental_option(\n",
    "    \"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument('lang=zh-CN,zh,zh-TW,en-US,en')\n",
    "chrome_options.add_argument(\n",
    "    'user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36')\n",
    "chrome_options.add_argument(\"disable-blink-features=AutomationControlled\")\n",
    "#proxy\n",
    "'''\n",
    "chrome_options.add_argument(\"proxy-server=socks5://127.0.0.1:1080\")\n",
    "preferences = {\n",
    "    \"webrtc.ip_handling_policy\": \"disable_non_proxied_udp\",\n",
    "    \"webrtc.multiple_routes_enabled\": False,\n",
    "    \"webrtc.nonproxied_udp_enabled\": False\n",
    "}\n",
    "'''\n",
    "\n",
    "#starts of the loop\n",
    "for keyword_row_num, keyword in enumerate(keyword_list):\n",
    "    \n",
    "    #test\n",
    "    if keyword_row_num == 0:\n",
    "        continue\n",
    "    \n",
    "    print(\"Keyword Check\")\n",
    "    \n",
    "    #start Chrome\n",
    "    driver = webdriver.Chrome(options=chrome_options)  \n",
    "    \n",
    "    print(\"Loop\",keyword_row_num,keyword)\n",
    "    #Start of fetch\n",
    "    ref_bank = ref_bank_list[keyword_row_num]\n",
    "    fetch_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S%f\")\n",
    "    #keyword_uid = \"LI-\"+str(fetch_datetime)+\"-\"+ str(keyword_row_num).zfill(8)\n",
    "    platform_uid = \"LI\"\n",
    "    fetch_uid = platform_uid+\"-\"+ str(fetch_datetime)\n",
    "\n",
    "    #get link\n",
    "    driver.get(f\"https://lihkg.com/search?q={keyword}&sort=desc_create_time&type=thread\")\n",
    "    time.sleep(4)\n",
    "    \n",
    "    #get html info\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    #click left panel for scrolling\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"leftPanel\"]/div[1]/ul/li[2]/a').click()\n",
    "\n",
    "    #Call the function and scroll to the end (leftpanel)\n",
    "    scroll_left_panel(driver)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #get latest html info\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    print(\"Start - loop thread\")\n",
    "    #get thread html info\n",
    "    threads = soup.find(\"div\",{\"class\":\"qoAmEqNpZRLf2KVKZ8DsC\"})\n",
    "    for thread_idx, i in enumerate(threads):\n",
    "        '''\n",
    "        ## CUSTOM STOP\n",
    "        if thread_idx == 3:\n",
    "            break\n",
    "        '''\n",
    "        \n",
    "        #click thread\n",
    "        click_thread(driver, thread_idx)\n",
    "        #give buffer incase the webpage use too much resource.\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #get thread info\n",
    "        try:\n",
    "            try:\n",
    "                thread_author = i.find(\"span\", {\"class\":\"CxY4XDSSItTeLVg0cKCN0 A0jheqYUBHNW93KykXKEH\"}).text\n",
    "            except:\n",
    "                thread_author = i.find(\"span\", {\"class\":\"CxY4XDSSItTeLVg0cKCN0 jj_3ZDzjtPixL1b2KTcpS\"}).text\n",
    "\n",
    "            thread_lastest_comment_time = i.find(\"span\", {\"class\":\"_37XwjAqVHtjzqzEtybpHrU\"}).text\n",
    "            thread_lastest_comment_time.replace('年',\"-\").replace('月', \"-\").replace('日', \"\")\n",
    "            \n",
    "            ###\n",
    "            #check day or hr or month function & break it when the time is not in range\n",
    "            #\n",
    "            #\n",
    "            ###\n",
    "\n",
    "            thread_title = i.find(\"span\", {\"class\":\"_20jopXBFHNQ9FUbcGHLcHH\"}).text\n",
    "            thread_page = i.find(\"div\", {\"class\":\"_26oEXjfUS_iHzbxYcZE6bD\"}).text.split(\" \")[0]\n",
    "            thread_theme = i.find_all(\"a\")[1].text\n",
    "            thread_total_like = driver.find_elements(By.CLASS_NAME, '_8_NT40G-QNQzcSSTrRXAD')[0].get_attribute('data-score')\n",
    "            thread_total_dislike = driver.find_elements(By.CLASS_NAME, '_8_NT40G-QNQzcSSTrRXAD')[1].get_attribute('data-score')\n",
    "            risk_type = risk_checker(str(thread_title).lower())\n",
    "            total_reaction = int(thread_total_like) + int(thread_total_dislike)\n",
    "            \n",
    "            print(thread_title)\n",
    "            angry = 'Null'\n",
    "            heart = 'Null'\n",
    "            haha ='Null'\n",
    "            goforit = 'Null'\n",
    "            cry = 'Null'\n",
    "            wow = 'Null'\n",
    "            org_emb_date = 'Null'\n",
    "            total_share = 'Null'\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        #Locate the thread in excel... if not exsit then keep going.. else exist and no update will skip it...\n",
    "        update_checker = True\n",
    "        try:\n",
    "            thread_exist_loc = df_distinct_thread_by_latest.loc[(df_distinct_thread_by_latest['Thread Author'] == thread_author) \n",
    "                                                                & (df_distinct_thread_by_latest['Thread Title'] == thread_title)\n",
    "                                                                & (df_distinct_thread_by_latest['Thread Theme'] == thread_theme)]\n",
    "\n",
    "            floor_number_pointer = thread_exist_loc[\"Comment Floor Number (Latest)\"].values[0]\n",
    "            previous_extract_latest_comment_time_pointer = thread_exist_loc[\"Thread Latest Comment Time\"].values[0]\n",
    "            print(f'Found... {floor_number_pointer}, {previous_extract_latest_comment_time_pointer}')\n",
    "\n",
    "            # Compare the time\n",
    "            # 1 Return True == need to update\n",
    "            # 2 Return False == skip it\n",
    "            update_checker = left_panel_date_check(previous_extract_latest_comment_time_pointer, thread_lastest_comment_time)\n",
    "            if update_checker == True:\n",
    "                print(update_checker, 'need updates')\n",
    "            \n",
    "            # if == to false the program stops after checking the post is it within the date range below...\n",
    "            if update_checker == False:\n",
    "                print(update_checker, 'no updates... check for the post date...')\n",
    "                #continue\n",
    "\n",
    "\n",
    "        except:\n",
    "            thread_exist = False\n",
    "            floor_number_pointer = '#0'\n",
    "            print('Not found... Set floor pointer to 0')\n",
    "    \n",
    "            \n",
    "            \n",
    "        #current time\n",
    "        fetch_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        #get the latest page info\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        \n",
    "        #check thread in range or not\n",
    "        date_out_of_range = check_thread_date_range(soup, user_customized_time_int_month)\n",
    "        if date_out_of_range == True:\n",
    "            print('Alert - Thread created date out of customized time range... Skip it...')\n",
    "            break\n",
    "        \n",
    "        # if no need update... skip after checking the date\n",
    "        if update_checker == False:\n",
    "            print(update_checker, 'Didnt exceed the range... continue the loop ')\n",
    "            continue\n",
    "        \n",
    "        #check the keyword is in the title or not\n",
    "        if str(keyword).lower() not in str(thread_title).lower():\n",
    "            print('Keyword not included in title... Skip it...')\n",
    "            continue        \n",
    "\n",
    "        print(f\"Start - {thread_page} Loop to end of the post\")\n",
    "        #loop to the end of pages\n",
    "        for click in range(int(thread_page)+3):\n",
    "            time.sleep(1)\n",
    "            test_html = driver.page_source\n",
    "            test_soup = BeautifulSoup(test_html)\n",
    "            test_all_comment = test_soup.find_all(\"div\",{\"class\":\"_36ZEkSvpdj_igmog0nluzh\"})\n",
    "            test_floor_pointer = test_all_comment[-1].find_all(\"span\")[0].text\n",
    "            \n",
    "            print(f\"{click} - Looping Check {test_floor_pointer}\")\n",
    "            try:\n",
    "                find_f5 = driver.find_element(By.CLASS_NAME, '_1PhR8JHkMcET5QT2PtCA3T')\n",
    "                actions = ActionChains(driver)\n",
    "                actions.move_to_element(find_f5).perform()\n",
    "            except:\n",
    "                try:\n",
    "                    find_f5 = driver.find_element(By.XPATH, f'//*[@id=\"page-{str(click+1)}\"]/div[3]/a').click()\n",
    "                except:\n",
    "                    for j in range(20):\n",
    "                        ActionChains(driver).send_keys(\" \").perform()\n",
    "            time.sleep(0.3)\n",
    "        print(\"End - loop to end of post\")\n",
    "\n",
    "        time.sleep(1)                \n",
    "        #get the latest page info\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        print(\"Start - Process Comment\")\n",
    "        #start of fetching comments data\n",
    "        all_comment = soup.find_all(\"div\",{\"class\":\"_36ZEkSvpdj_igmog0nluzh\"})\n",
    "        for comment_idx , comment in enumerate(all_comment):\n",
    "            \n",
    "            #print(\"Loop - Process Comment\")\n",
    "            \n",
    "            comment_floor_number = comment.find_all(\"span\")[0].text\n",
    "            comment_author = comment.find(\"span\",{\"class\":\"ZZtOrmcIRcvdpnW09DzFk\"}).text\n",
    "\n",
    "            #incase the comment is folded due to not enough info\n",
    "            try:\n",
    "                comment_datetime = comment.find(\"span\",{\"class\":\"Ahi80YgykKo22njTSCzs_\"})\n",
    "                new_comment_datetime = str(comment_datetime).split(\"\\\"\")[5]\n",
    "                new_comment_datetime = new_comment_datetime.replace('年',\"-\").replace('月', \"-\").replace('日', \"\")\n",
    "                comment_date = new_comment_datetime.split(\" \")[0]\n",
    "                comment_time = new_comment_datetime.split(\" \")[1]\n",
    "\n",
    "                comment_like = comment.find_all(\"label\")[1].text\n",
    "                comment_dislike = comment.find_all(\"label\")[3].text\n",
    "            except:\n",
    "                comment_datetime = \"\"\n",
    "                comment_date = ''\n",
    "                comment_time = ''\n",
    "                comment_like = 0\n",
    "                comment_dislike = 0\n",
    "\n",
    "            try:\n",
    "                comment_replies = comment.find_all(\"label\")[5].text\n",
    "            except:\n",
    "                comment_replies = 0\n",
    "\n",
    "            try:\n",
    "                comment_context = comment.find(\"div\",{\"class\":\"_2cNsJna0_hV8tdMj3X6_gJ\"}).text\n",
    "            except:\n",
    "                comment_context = ''\n",
    "\n",
    "            \n",
    "            #find earliest time\n",
    "            if comment_idx == 0:\n",
    "                thread_post_datetime = new_comment_datetime\n",
    "                \n",
    "                #thread UID\n",
    "                thread_uid = thread_author + \"-\" + thread_theme + \"-\" + thread_title + \"-\" + thread_post_datetime\n",
    "\n",
    "            \n",
    "            comment_uid = thread_uid + \"-\" + str(comment_floor_number.replace(\"#\", \"\")).zfill(8)\n",
    "\n",
    "            #get the lastest comment time\n",
    "            latest_comment_time = new_comment_datetime\n",
    "                \n",
    "            #get lastest floor number in this fetch\n",
    "            lastest_floor_number = comment_floor_number\n",
    "            \n",
    "\n",
    "            \n",
    "            #current time\n",
    "            fetch_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "            \n",
    "            #compare the latest floor number\n",
    "            if int(floor_number_pointer.replace(\"#\", \"\")) < int(comment_floor_number.replace(\"#\", \"\")):\n",
    "                print(floor_number_pointer, comment_floor_number)\n",
    "                comment_updates = True\n",
    "                ### do the word segmentation and get comment contain foul or not\n",
    "                comment_foul = words_segmentation(keywords_NLP_set,\n",
    "                                                  foul_keywords,\n",
    "                                                  skip_keywords,\n",
    "                                                  comment_context,\n",
    "                                                  comment_uid,\n",
    "                                                  new_comment_datetime)\n",
    "                \n",
    "                translated_context = translate_to_en(comment_context)\n",
    "                \n",
    "                #####\n",
    "                #Scrapy Sentiment check\n",
    "                #sentiment, sentiment_score, perception, perception_score = sentiment_check(translated_context)\n",
    "                #####\n",
    "                \n",
    "                #Vader Sentiment Check\n",
    "                sentiment, sentiment_score = vader_sentiment(translated_context)\n",
    "                #Risk Type\n",
    "                comment_risk_type = risk_checker(comment_context)\n",
    "                \n",
    "                #total comment (by this fetch)\n",
    "                num_of_comment = int(lastest_floor_number.replace(\"#\", ''))\n",
    "\n",
    "                \n",
    "                df_comments.loc[len(df_comments)]= [thread_uid,\n",
    "                                                     comment_uid,\n",
    "                                                     fetch_datetime,\n",
    "                                                     comment_floor_number,\n",
    "                                                     comment_author,\n",
    "                                                     org_emb_date,\n",
    "                                                     new_comment_datetime,\n",
    "                                                     comment_date,\n",
    "                                                     comment_time,\n",
    "                                                     int(comment_like),\n",
    "                                                     int(comment_dislike), \n",
    "                                                     int(comment_replies), \n",
    "                                                     comment_context,\n",
    "                                                     translated_context,\n",
    "                                                     sentiment, \n",
    "                                                     sentiment_score, \n",
    "                                                     comment_risk_type,\n",
    "                                                     #perception, \n",
    "                                                     #perception_score,                                                    \n",
    "                                                     comment_foul]\n",
    "                \n",
    "            else:\n",
    "                comment_updates = False\n",
    "        print(\"After process all comment in a thread \")\n",
    "        \n",
    "        \n",
    "        if comment_updates == True:\n",
    "            #save thread into to dataframe\n",
    "            df_thread_log.loc[len(df_thread_log)]= [platform_uid,\n",
    "                                              thread_uid,\n",
    "                                              keyword,\n",
    "                                              ref_bank,                                         \n",
    "                                              thread_post_datetime,\n",
    "                                              thread_author, \n",
    "                                              thread_title,\n",
    "                                              thread_theme,\n",
    "                                              lastest_floor_number,\n",
    "                                              risk_type,\n",
    "                                              latest_comment_time]\n",
    "\n",
    "\n",
    "\n",
    "            df_fetch_log.loc[len(df_fetch_log)]= [fetch_uid,\n",
    "                                              thread_uid,\n",
    "                                              fetch_datetime,                                          \n",
    "                                              thread_lastest_comment_time,\n",
    "                                              latest_comment_time,\n",
    "                                              int(thread_page),\n",
    "                                              total_share,\n",
    "                                              total_reaction,\n",
    "                                              int(thread_total_like), \n",
    "                                              int(thread_total_dislike),\n",
    "                                              angry,\n",
    "                                              heart,\n",
    "                                              haha,\n",
    "                                              goforit,\n",
    "                                              cry,\n",
    "                                              wow,\n",
    "                                              num_of_comment]\n",
    "            \n",
    "            print(\"End of this thread Check\")\n",
    "    \n",
    "    \n",
    "        if thread_idx == 3:\n",
    "            break\n",
    "    \n",
    "    if keyword_row_num == 1:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    driver.quit()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8d0bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform UID</th>\n",
       "      <th>Thread UID (PK)</th>\n",
       "      <th>Search Keyword</th>\n",
       "      <th>Reference Bank</th>\n",
       "      <th>Thread Create Datetime</th>\n",
       "      <th>Thread Author</th>\n",
       "      <th>Thread Title</th>\n",
       "      <th>Thread Theme</th>\n",
       "      <th>Comment Floor Number (Latest)</th>\n",
       "      <th>Risk Type</th>\n",
       "      <th>Thread Latest Comment Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16</td>\n",
       "      <td>渣打</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>舉頭三尺有神棍</td>\n",
       "      <td>垃圾渣打萬事達卡 準備Cut卡</td>\n",
       "      <td>吹水台</td>\n",
       "      <td>#3</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>2023-2-21 19:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI</td>\n",
       "      <td>聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28</td>\n",
       "      <td>渣打</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "      <td>2023-2-18 08:25:28</td>\n",
       "      <td>聖誕緣份計劃</td>\n",
       "      <td>［求救］渣打係日本提唔到款</td>\n",
       "      <td>旅遊台</td>\n",
       "      <td>#25</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>2023-2-18 08:50:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI</td>\n",
       "      <td>狗肉師-上班台-公司個後生仔跑完渣打話想請半日假-2023-2-14 11:07:59</td>\n",
       "      <td>渣打</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "      <td>2023-2-14 11:07:59</td>\n",
       "      <td>狗肉師</td>\n",
       "      <td>公司個後生仔跑完渣打話想請半日假</td>\n",
       "      <td>上班台</td>\n",
       "      <td>#25</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>2023-2-14 14:39:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI</td>\n",
       "      <td>未踢孫興奮-上班台-有無巴絲打做緊渣打有個位叫business executive？-202...</td>\n",
       "      <td>渣打</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "      <td>2023-2-14 00:18:44</td>\n",
       "      <td>未踢孫興奮</td>\n",
       "      <td>有無巴絲打做緊渣打有個位叫business executive？</td>\n",
       "      <td>上班台</td>\n",
       "      <td>#7</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>2023-2-16 00:21:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI</td>\n",
       "      <td>囝細老婆嫩-吹水台-睇嚟揸兜今日好唔掂喎⋯⋯-2022-12-7 22:45:04</td>\n",
       "      <td>揸兜</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "      <td>2022-12-7 22:45:04</td>\n",
       "      <td>囝細老婆嫩</td>\n",
       "      <td>睇嚟揸兜今日好唔掂喎⋯⋯</td>\n",
       "      <td>吹水台</td>\n",
       "      <td>#4</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>2022-12-7 23:15:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LI</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>揸兜</td>\n",
       "      <td>Standard Chartered Hong Kong</td>\n",
       "      <td>2022-12-6 21:04:25</td>\n",
       "      <td>神宮寺</td>\n",
       "      <td>揸兜信用卡比人碌到錢</td>\n",
       "      <td>財經台</td>\n",
       "      <td>#150</td>\n",
       "      <td>Technology Risk</td>\n",
       "      <td>2022-12-6 23:14:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform UID                                    Thread UID (PK)  \\\n",
       "0           LI     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16   \n",
       "1           LI        聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28   \n",
       "2           LI        狗肉師-上班台-公司個後生仔跑完渣打話想請半日假-2023-2-14 11:07:59   \n",
       "3           LI  未踢孫興奮-上班台-有無巴絲打做緊渣打有個位叫business executive？-202...   \n",
       "4           LI          囝細老婆嫩-吹水台-睇嚟揸兜今日好唔掂喎⋯⋯-2022-12-7 22:45:04   \n",
       "5           LI              神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25   \n",
       "\n",
       "  Search Keyword                Reference Bank Thread Create Datetime  \\\n",
       "0             渣打  Standard Chartered Hong Kong     2023-2-21 18:10:16   \n",
       "1             渣打  Standard Chartered Hong Kong     2023-2-18 08:25:28   \n",
       "2             渣打  Standard Chartered Hong Kong     2023-2-14 11:07:59   \n",
       "3             渣打  Standard Chartered Hong Kong     2023-2-14 00:18:44   \n",
       "4             揸兜  Standard Chartered Hong Kong     2022-12-7 22:45:04   \n",
       "5             揸兜  Standard Chartered Hong Kong     2022-12-6 21:04:25   \n",
       "\n",
       "  Thread Author                      Thread Title Thread Theme  \\\n",
       "0       舉頭三尺有神棍                   垃圾渣打萬事達卡 準備Cut卡          吹水台   \n",
       "1        聖誕緣份計劃                     ［求救］渣打係日本提唔到款          旅遊台   \n",
       "2           狗肉師                  公司個後生仔跑完渣打話想請半日假          上班台   \n",
       "3         未踢孫興奮  有無巴絲打做緊渣打有個位叫business executive？          上班台   \n",
       "4         囝細老婆嫩                      睇嚟揸兜今日好唔掂喎⋯⋯          吹水台   \n",
       "5           神宮寺                        揸兜信用卡比人碌到錢          財經台   \n",
       "\n",
       "  Comment Floor Number (Latest)        Risk Type Thread Latest Comment Time  \n",
       "0                            #3     Unidentified         2023-2-21 19:08:10  \n",
       "1                           #25     Unidentified         2023-2-18 08:50:14  \n",
       "2                           #25     Unidentified         2023-2-14 14:39:27  \n",
       "3                            #7     Unidentified         2023-2-16 00:21:12  \n",
       "4                            #4     Unidentified         2022-12-7 23:15:47  \n",
       "5                          #150  Technology Risk         2022-12-6 23:14:46  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62cf35b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fetch UID (PK)</th>\n",
       "      <th>Thread UID (FK)</th>\n",
       "      <th>Fetch Datetime</th>\n",
       "      <th>Thread Latest Comment Time(Thread info)</th>\n",
       "      <th>Thread Latest Comment Time(Fetch inside comment)</th>\n",
       "      <th>Thread Number of Page</th>\n",
       "      <th>Number of Share</th>\n",
       "      <th>Number of Reactions</th>\n",
       "      <th>Thread Likes</th>\n",
       "      <th>Thread Dislike</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Heart</th>\n",
       "      <th>HaHa</th>\n",
       "      <th>Go For It</th>\n",
       "      <th>Cry</th>\n",
       "      <th>WOW</th>\n",
       "      <th>Number of Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI-20230222-134028146806</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16</td>\n",
       "      <td>2023-02-22 13:41:38</td>\n",
       "      <td>18 小時前</td>\n",
       "      <td>2023-2-21 19:08:10</td>\n",
       "      <td>1</td>\n",
       "      <td>Null</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI-20230222-134028146806</td>\n",
       "      <td>聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28</td>\n",
       "      <td>2023-02-22 13:44:19</td>\n",
       "      <td>3 小時前</td>\n",
       "      <td>2023-2-18 08:50:14</td>\n",
       "      <td>18</td>\n",
       "      <td>Null</td>\n",
       "      <td>249</td>\n",
       "      <td>10</td>\n",
       "      <td>239</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI-20230222-134028146806</td>\n",
       "      <td>狗肉師-上班台-公司個後生仔跑完渣打話想請半日假-2023-2-14 11:07:59</td>\n",
       "      <td>2023-02-22 13:44:59</td>\n",
       "      <td>7 日前</td>\n",
       "      <td>2023-2-14 14:39:27</td>\n",
       "      <td>2</td>\n",
       "      <td>Null</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI-20230222-134028146806</td>\n",
       "      <td>未踢孫興奮-上班台-有無巴絲打做緊渣打有個位叫business executive？-202...</td>\n",
       "      <td>2023-02-22 13:45:30</td>\n",
       "      <td>6 日前</td>\n",
       "      <td>2023-2-16 00:21:12</td>\n",
       "      <td>1</td>\n",
       "      <td>Null</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI-20230222-134537578809</td>\n",
       "      <td>囝細老婆嫩-吹水台-睇嚟揸兜今日好唔掂喎⋯⋯-2022-12-7 22:45:04</td>\n",
       "      <td>2023-02-22 13:46:22</td>\n",
       "      <td>2 個月前</td>\n",
       "      <td>2022-12-7 23:15:47</td>\n",
       "      <td>1</td>\n",
       "      <td>Null</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LI-20230222-134537578809</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>2023-02-22 13:48:06</td>\n",
       "      <td>2 個月前</td>\n",
       "      <td>2022-12-6 23:14:46</td>\n",
       "      <td>41</td>\n",
       "      <td>Null</td>\n",
       "      <td>498</td>\n",
       "      <td>33</td>\n",
       "      <td>465</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fetch UID (PK)  \\\n",
       "0  LI-20230222-134028146806   \n",
       "1  LI-20230222-134028146806   \n",
       "2  LI-20230222-134028146806   \n",
       "3  LI-20230222-134028146806   \n",
       "4  LI-20230222-134537578809   \n",
       "5  LI-20230222-134537578809   \n",
       "\n",
       "                                     Thread UID (FK)       Fetch Datetime  \\\n",
       "0     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16  2023-02-22 13:41:38   \n",
       "1        聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28  2023-02-22 13:44:19   \n",
       "2        狗肉師-上班台-公司個後生仔跑完渣打話想請半日假-2023-2-14 11:07:59  2023-02-22 13:44:59   \n",
       "3  未踢孫興奮-上班台-有無巴絲打做緊渣打有個位叫business executive？-202...  2023-02-22 13:45:30   \n",
       "4          囝細老婆嫩-吹水台-睇嚟揸兜今日好唔掂喎⋯⋯-2022-12-7 22:45:04  2023-02-22 13:46:22   \n",
       "5              神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25  2023-02-22 13:48:06   \n",
       "\n",
       "  Thread Latest Comment Time(Thread info)  \\\n",
       "0                                  18 小時前   \n",
       "1                                   3 小時前   \n",
       "2                                    7 日前   \n",
       "3                                    6 日前   \n",
       "4                                   2 個月前   \n",
       "5                                   2 個月前   \n",
       "\n",
       "  Thread Latest Comment Time(Fetch inside comment)  Thread Number of Page  \\\n",
       "0                               2023-2-21 19:08:10                      1   \n",
       "1                               2023-2-18 08:50:14                     18   \n",
       "2                               2023-2-14 14:39:27                      2   \n",
       "3                               2023-2-16 00:21:12                      1   \n",
       "4                               2022-12-7 23:15:47                      1   \n",
       "5                               2022-12-6 23:14:46                     41   \n",
       "\n",
       "  Number of Share  Number of Reactions  Thread Likes  Thread Dislike Angry  \\\n",
       "0            Null                    3             0               3  Null   \n",
       "1            Null                  249            10             239  Null   \n",
       "2            Null                   64             9              55  Null   \n",
       "3            Null                    0             0               0  Null   \n",
       "4            Null                    2             2               0  Null   \n",
       "5            Null                  498            33             465  Null   \n",
       "\n",
       "  Heart  HaHa Go For It   Cry   WOW  Number of Comment  \n",
       "0  Null  Null      Null  Null  Null                  3  \n",
       "1  Null  Null      Null  Null  Null                 25  \n",
       "2  Null  Null      Null  Null  Null                 25  \n",
       "3  Null  Null      Null  Null  Null                  7  \n",
       "4  Null  Null      Null  Null  Null                  4  \n",
       "5  Null  Null      Null  Null  Null                150  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fetch_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b8ade4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread UID (FK)</th>\n",
       "      <th>Comment UID (PK)</th>\n",
       "      <th>Fetch Datetime</th>\n",
       "      <th>Comment Floor Number</th>\n",
       "      <th>Comment Author</th>\n",
       "      <th>Original Embedded Date</th>\n",
       "      <th>Comment Datetime</th>\n",
       "      <th>Comment Date</th>\n",
       "      <th>Comment Time</th>\n",
       "      <th>Comment Likes</th>\n",
       "      <th>Comment Dislike</th>\n",
       "      <th>Comment Replies</th>\n",
       "      <th>Comment Context</th>\n",
       "      <th>Comment Context (Translated)</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Risk Type (Comment Level)</th>\n",
       "      <th>Offensive Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-02-22 13:41:35</td>\n",
       "      <td>#1</td>\n",
       "      <td>舉頭三尺有神棍</td>\n",
       "      <td>Null</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>2023-2-21</td>\n",
       "      <td>18:10:16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>你滷味 本身儲咗5萬幾里數 冧住用里數換機票飛日本\\n點知根本冇航班可以換到 \\n里數加現金...</td>\n",
       "      <td>You have accumulated 50,000 miles in your lo m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.7906</td>\n",
       "      <td>Credit Risk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-02-22 13:41:38</td>\n",
       "      <td>#2</td>\n",
       "      <td>修尼皮先生</td>\n",
       "      <td>Null</td>\n",
       "      <td>2023-2-21 18:54:50</td>\n",
       "      <td>2023-2-21</td>\n",
       "      <td>18:54:50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>連俾錢買位都貴過hihi\\n邊會有位留返俾人redeem</td>\n",
       "      <td>Even paying for a seat is more expensive than ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-02-22 13:41:38</td>\n",
       "      <td>#3</td>\n",
       "      <td>NYCyee</td>\n",
       "      <td>Null</td>\n",
       "      <td>2023-2-21 19:08:10</td>\n",
       "      <td>2023-2-21</td>\n",
       "      <td>19:08:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>宜家唔知係唔係間間都差唔多, 英航既卡都係咁呢</td>\n",
       "      <td>I don’t know if it’s the same or not, but the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28</td>\n",
       "      <td>聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28-00...</td>\n",
       "      <td>2023-02-22 13:44:10</td>\n",
       "      <td>#1</td>\n",
       "      <td>聖誕緣份計劃</td>\n",
       "      <td>Null</td>\n",
       "      <td>2023-2-18 08:25:28</td>\n",
       "      <td>2023-2-18</td>\n",
       "      <td>08:25:28</td>\n",
       "      <td>10</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>提款卡明明申請左海外提款，去大阪用過三井同seven支援銀聯既atm，都話無存款，但明明個戶...</td>\n",
       "      <td>The ATM card is clearly applied for overseas w...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>Technology Risk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28</td>\n",
       "      <td>聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28-00...</td>\n",
       "      <td>2023-02-22 13:44:10</td>\n",
       "      <td>#2</td>\n",
       "      <td>藍沢エマ</td>\n",
       "      <td>Null</td>\n",
       "      <td>2023-2-18 08:30:34</td>\n",
       "      <td>2023-2-18</td>\n",
       "      <td>08:30:34</td>\n",
       "      <td>321</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>其實大部份銀行既海外提款都係即時用港幣兌，只有小部份銀行先可以拎原幣</td>\n",
       "      <td>In fact, most banks use Hong Kong dollars for ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000146</td>\n",
       "      <td>2023-02-22 13:48:05</td>\n",
       "      <td>#146</td>\n",
       "      <td>在水中央</td>\n",
       "      <td>Null</td>\n",
       "      <td>2022-12-6 23:13:27</td>\n",
       "      <td>2022-12-6</td>\n",
       "      <td>23:13:27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>岩岩比人碌左18鎂</td>\n",
       "      <td>Yanyan Birenlu Zuo 18 mg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000147</td>\n",
       "      <td>2023-02-22 13:48:05</td>\n",
       "      <td>#147</td>\n",
       "      <td>肥婆分割技術員</td>\n",
       "      <td>Null</td>\n",
       "      <td>2022-12-6 23:13:33</td>\n",
       "      <td>2022-12-6</td>\n",
       "      <td>23:13:33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>一單 9.65鎂</td>\n",
       "      <td>1 single 9.65 mg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000148</td>\n",
       "      <td>2023-02-22 13:48:05</td>\n",
       "      <td>#148</td>\n",
       "      <td>TommyWiseau</td>\n",
       "      <td>Null</td>\n",
       "      <td>2022-12-6 23:13:55</td>\n",
       "      <td>2022-12-6</td>\n",
       "      <td>23:13:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>要OTP嗰啲先會收到，如果唔使嗰啲真係好似冇\\n\\n因為我本身係無啦啦俾佢停了張卡，打返去問...</td>\n",
       "      <td>Those who want OTP will receive it first, if n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.9365</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149</td>\n",
       "      <td>2023-02-22 13:48:06</td>\n",
       "      <td>#149</td>\n",
       "      <td>小証</td>\n",
       "      <td>Null</td>\n",
       "      <td>2022-12-6 23:13:59</td>\n",
       "      <td>2022-12-6</td>\n",
       "      <td>23:13:59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>今日咁多人中招，似乎真係SCB 有野</td>\n",
       "      <td>So many people have been recruited today, it s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150</td>\n",
       "      <td>2023-02-22 13:48:06</td>\n",
       "      <td>#150</td>\n",
       "      <td>祖·拜登</td>\n",
       "      <td>Null</td>\n",
       "      <td>2022-12-6 23:14:46</td>\n",
       "      <td>2022-12-6</td>\n",
       "      <td>23:14:46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>鎖咗先 唔係陣間又碌你</td>\n",
       "      <td>Lock it first, don't wait for a while and busy...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unidentified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Thread UID (FK)  \\\n",
       "0    舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16   \n",
       "1    舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16   \n",
       "2    舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16   \n",
       "3       聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28   \n",
       "4       聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28   \n",
       "..                                              ...   \n",
       "198           神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25   \n",
       "199           神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25   \n",
       "200           神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25   \n",
       "201           神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25   \n",
       "202           神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25   \n",
       "\n",
       "                                      Comment UID (PK)       Fetch Datetime  \\\n",
       "0    舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-02-22 13:41:35   \n",
       "1    舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-02-22 13:41:38   \n",
       "2    舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-02-22 13:41:38   \n",
       "3    聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28-00...  2023-02-22 13:44:10   \n",
       "4    聖誕緣份計劃-旅遊台-［求救］渣打係日本提唔到款-2023-2-18 08:25:28-00...  2023-02-22 13:44:10   \n",
       "..                                                 ...                  ...   \n",
       "198     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000146  2023-02-22 13:48:05   \n",
       "199     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000147  2023-02-22 13:48:05   \n",
       "200     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000148  2023-02-22 13:48:05   \n",
       "201     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149  2023-02-22 13:48:06   \n",
       "202     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150  2023-02-22 13:48:06   \n",
       "\n",
       "    Comment Floor Number Comment Author Original Embedded Date  \\\n",
       "0                     #1        舉頭三尺有神棍                   Null   \n",
       "1                     #2          修尼皮先生                   Null   \n",
       "2                     #3         NYCyee                   Null   \n",
       "3                     #1         聖誕緣份計劃                   Null   \n",
       "4                     #2           藍沢エマ                   Null   \n",
       "..                   ...            ...                    ...   \n",
       "198                 #146           在水中央                   Null   \n",
       "199                 #147        肥婆分割技術員                   Null   \n",
       "200                 #148    TommyWiseau                   Null   \n",
       "201                 #149             小証                   Null   \n",
       "202                 #150           祖·拜登                   Null   \n",
       "\n",
       "       Comment Datetime Comment Date Comment Time  Comment Likes  \\\n",
       "0    2023-2-21 18:10:16    2023-2-21     18:10:16              0   \n",
       "1    2023-2-21 18:54:50    2023-2-21     18:54:50              1   \n",
       "2    2023-2-21 19:08:10    2023-2-21     19:08:10              0   \n",
       "3    2023-2-18 08:25:28    2023-2-18     08:25:28             10   \n",
       "4    2023-2-18 08:30:34    2023-2-18     08:30:34            321   \n",
       "..                  ...          ...          ...            ...   \n",
       "198  2022-12-6 23:13:27    2022-12-6     23:13:27              2   \n",
       "199  2022-12-6 23:13:33    2022-12-6     23:13:33              1   \n",
       "200  2022-12-6 23:13:55    2022-12-6     23:13:55              0   \n",
       "201  2022-12-6 23:13:59    2022-12-6     23:13:59              2   \n",
       "202  2022-12-6 23:14:46    2022-12-6     23:14:46              0   \n",
       "\n",
       "     Comment Dislike  Comment Replies  \\\n",
       "0                  3                0   \n",
       "1                  0                0   \n",
       "2                  0                0   \n",
       "3                239                0   \n",
       "4                  9                5   \n",
       "..               ...              ...   \n",
       "198                0                0   \n",
       "199                0                0   \n",
       "200                0                0   \n",
       "201                0                0   \n",
       "202                0                1   \n",
       "\n",
       "                                       Comment Context  \\\n",
       "0    你滷味 本身儲咗5萬幾里數 冧住用里數換機票飛日本\\n點知根本冇航班可以換到 \\n里數加現金...   \n",
       "1                         連俾錢買位都貴過hihi\\n邊會有位留返俾人redeem   \n",
       "2                              宜家唔知係唔係間間都差唔多, 英航既卡都係咁呢   \n",
       "3    提款卡明明申請左海外提款，去大阪用過三井同seven支援銀聯既atm，都話無存款，但明明個戶...   \n",
       "4                   其實大部份銀行既海外提款都係即時用港幣兌，只有小部份銀行先可以拎原幣   \n",
       "..                                                 ...   \n",
       "198                                          岩岩比人碌左18鎂   \n",
       "199                                           一單 9.65鎂   \n",
       "200  要OTP嗰啲先會收到，如果唔使嗰啲真係好似冇\\n\\n因為我本身係無啦啦俾佢停了張卡，打返去問...   \n",
       "201                                 今日咁多人中招，似乎真係SCB 有野   \n",
       "202                                        鎖咗先 唔係陣間又碌你   \n",
       "\n",
       "                          Comment Context (Translated) Sentiment  \\\n",
       "0    You have accumulated 50,000 miles in your lo m...  negative   \n",
       "1    Even paying for a seat is more expensive than ...   neutral   \n",
       "2    I don’t know if it’s the same or not, but the ...   neutral   \n",
       "3    The ATM card is clearly applied for overseas w...  positive   \n",
       "4    In fact, most banks use Hong Kong dollars for ...  positive   \n",
       "..                                                 ...       ...   \n",
       "198                           Yanyan Birenlu Zuo 18 mg   neutral   \n",
       "199                                   1 single 9.65 mg   neutral   \n",
       "200  Those who want OTP will receive it first, if n...  negative   \n",
       "201  So many people have been recruited today, it s...   neutral   \n",
       "202  Lock it first, don't wait for a while and busy...   neutral   \n",
       "\n",
       "     Sentiment Score Risk Type (Comment Level)  Offensive Comment  \n",
       "0            -0.7906               Credit Risk              False  \n",
       "1             0.0000              Unidentified              False  \n",
       "2             0.0000              Unidentified              False  \n",
       "3             0.2846           Technology Risk              False  \n",
       "4             0.3818              Unidentified              False  \n",
       "..               ...                       ...                ...  \n",
       "198           0.0000              Unidentified              False  \n",
       "199           0.0000              Unidentified              False  \n",
       "200          -0.9365              Unidentified              False  \n",
       "201           0.0000              Unidentified              False  \n",
       "202           0.0000              Unidentified              False  \n",
       "\n",
       "[203 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60bf237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word UID (PK)</th>\n",
       "      <th>Comment UID (FK)</th>\n",
       "      <th>Datetime (Comment)</th>\n",
       "      <th>Language</th>\n",
       "      <th>Part of Speech Tagging</th>\n",
       "      <th>Word</th>\n",
       "      <th>Foul Language</th>\n",
       "      <th>Risk Type (Word Level)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>zh</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>滷味</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>zh</td>\n",
       "      <td>VERB</td>\n",
       "      <td>儲</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>en</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>zh</td>\n",
       "      <td>VERB</td>\n",
       "      <td>冧</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...</td>\n",
       "      <td>2023-2-21 18:10:16</td>\n",
       "      <td>zh</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>里數</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149...</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149</td>\n",
       "      <td>2022-12-6 23:13:59</td>\n",
       "      <td>zh</td>\n",
       "      <td>VERB</td>\n",
       "      <td>似乎</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149...</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149</td>\n",
       "      <td>2022-12-6 23:13:59</td>\n",
       "      <td>en</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Scb</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150...</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150</td>\n",
       "      <td>2022-12-6 23:14:46</td>\n",
       "      <td>zh</td>\n",
       "      <td>VERB</td>\n",
       "      <td>鎖</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150...</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150</td>\n",
       "      <td>2022-12-6 23:14:46</td>\n",
       "      <td>zh</td>\n",
       "      <td>VERB</td>\n",
       "      <td>唔係</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150...</td>\n",
       "      <td>神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150</td>\n",
       "      <td>2022-12-6 23:14:46</td>\n",
       "      <td>zh</td>\n",
       "      <td>VERB</td>\n",
       "      <td>碌</td>\n",
       "      <td>False</td>\n",
       "      <td>Unidentified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Word UID (PK)  \\\n",
       "0     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...   \n",
       "1     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...   \n",
       "2     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...   \n",
       "3     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...   \n",
       "4     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...   \n",
       "...                                                 ...   \n",
       "1595  神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149...   \n",
       "1596  神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149...   \n",
       "1597  神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150...   \n",
       "1598  神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150...   \n",
       "1599  神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150...   \n",
       "\n",
       "                                       Comment UID (FK)  Datetime (Comment)  \\\n",
       "0     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-2-21 18:10:16   \n",
       "1     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-2-21 18:10:16   \n",
       "2     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-2-21 18:10:16   \n",
       "3     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-2-21 18:10:16   \n",
       "4     舉頭三尺有神棍-吹水台-垃圾渣打萬事達卡 準備Cut卡-2023-2-21 18:10:16...  2023-2-21 18:10:16   \n",
       "...                                                 ...                 ...   \n",
       "1595     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149  2022-12-6 23:13:59   \n",
       "1596     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000149  2022-12-6 23:13:59   \n",
       "1597     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150  2022-12-6 23:14:46   \n",
       "1598     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150  2022-12-6 23:14:46   \n",
       "1599     神宮寺-財經台-揸兜信用卡比人碌到錢-2022-12-6 21:04:25-00000150  2022-12-6 23:14:46   \n",
       "\n",
       "     Language Part of Speech Tagging Word  Foul Language  \\\n",
       "0          zh                   NOUN   滷味          False   \n",
       "1          zh                   VERB    儲          False   \n",
       "2          en                   NOUN    5          False   \n",
       "3          zh                   VERB    冧          False   \n",
       "4          zh                   NOUN   里數          False   \n",
       "...       ...                    ...  ...            ...   \n",
       "1595       zh                   VERB   似乎          False   \n",
       "1596       en                   NOUN  Scb          False   \n",
       "1597       zh                   VERB    鎖          False   \n",
       "1598       zh                   VERB   唔係          False   \n",
       "1599       zh                   VERB    碌          False   \n",
       "\n",
       "     Risk Type (Word Level)  \n",
       "0              Unidentified  \n",
       "1              Unidentified  \n",
       "2              Unidentified  \n",
       "3              Unidentified  \n",
       "4              Unidentified  \n",
       "...                     ...  \n",
       "1595           Unidentified  \n",
       "1596           Unidentified  \n",
       "1597           Unidentified  \n",
       "1598           Unidentified  \n",
       "1599           Unidentified  \n",
       "\n",
       "[1600 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c109db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Admin/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#output data\n",
    "#drop duplicated thread\n",
    "df_thread_log.drop_duplicates(keep = 'last')\n",
    "df_thread_log.to_excel(f'{ma_storage_dsl_path}Thread_Log.xlsx',encoding= 'utf-8-sig',index = None) \n",
    "\n",
    "df_fetch_log.to_excel(f'{ma_storage_dsl_path}Fetch_Log.xlsx',encoding= 'utf-8-sig',index = None) \n",
    "df_comments.to_excel(f'{ma_storage_dsl_path}Comment_Log.xlsx',encoding= 'utf-8-sig',index = None) \n",
    "df_words.to_excel(f'{ma_storage_dsl_path}Segmented_Words.xlsx',encoding= 'utf-8-sig',index = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8c9fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Admin/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#read and save it without null, need to find another way be smart\n",
    "df_comments = pd.read_excel(f'{ma_storage_dsl_path}Comment_Log.xlsx')\n",
    "#drop null value\n",
    "df_comments = df_comments.dropna()\n",
    "df_comments.to_excel(f'{ma_storage_dsl_path}Comment_Log.xlsx',encoding= 'utf-8-sig',index = None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d2b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
